# ğŸ™ï¸ Amharic Speech-to-Text & Tone Detection for Call Centers

This project provides **real-time Amharic speech transcription** and **tone detection** for **direct call center support**.  
Built with **FastAPI (Python)** for the backend and **React** for the frontend.  

---

## ğŸš€ Features
- ğŸ¤ **Real-Time Speech-to-Text (STT)** â€” Optimized for **Amharic language**.
- ğŸ¯ **Tone Detection** â€” Detects sentiment/tone during calls:
  - ğŸŸ¢ Positive  
  - ğŸŸ¡ Neutral  
  - ğŸ”´ Negative
- ğŸ“¡ **WebSocket Integration** â€” Enables **live captions** while recording or during a call.
- ğŸ§ **File Upload Support** â€” Supports audio formats:
  - `WAV`, `MP3`, `MP4`, `M4A`, `OGG`, `FLAC`, `AAC`, `WMA`
- ğŸ’¾ **High-Quality Recording** â€” Call recordings are saved in `.wav`.
- ğŸ¢ **Call Center Use Case** â€” Agents get **instant transcription + tone insight**.



## ğŸ¯ Call Center Use Cases  
- **Customer Support** â†’ Detect frustrated customers early and alert supervisors  
- **Quality Monitoring** â†’ Analyze tone & emotion across calls to measure satisfaction  
- **Training Agents** â†’ Improve handling skills by reviewing tone + transcripts  
- **Compliance** â†’ Store transcripts for auditing while analyzing customer emotions  

---

## ğŸ“¸ Demo Screenshot  

<img width="2448" height="1139" alt="image" src="https://github.com/user-attachments/assets/388df45b-9274-47ea-acb4-95bb2cbfc1e4" />

<img width="1853" height="1085" alt="image" src="https://github.com/user-attachments/assets/0a55aa1b-3af5-4efb-a95b-74d63338bfde" />


*(Replace with a screenshot of live call transcription + tone indicator)*  

---

## ğŸ› ï¸ Installation  

```bash
# Clone repo
git clone https://github.com/your-username/amharic-callcenter-support.git
cd amharic-callcenter-support

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
---

## ğŸ› ï¸ Tech Stack
- **Backend** â†’ [FastAPI](https://fastapi.tiangolo.com/) (Python)  
- **Frontend** â†’ [React](https://reactjs.org/)  
- **Speech-to-Text Engine** â†’ (Whisper / Wav2Vec / Custom Amharic model)  
- **Tone Detection** â†’ Transformer-based sentiment model  
- **Database (optional)** â†’ PostgreSQL / MongoDB for storing transcripts  

---

## ğŸ“‚ Project Structure
```bash
amharic-speech-tone/
â”‚â”€â”€ backend/              # FastAPI server
â”‚   â”œâ”€â”€ main.py           # API endpoints & WebSocket
â”‚   â”œâ”€â”€ stt_model.py      # Speech-to-Text model
â”‚   â”œâ”€â”€ tone_model.py     # Tone detection model
â”‚   â””â”€â”€ requirements.txt  # Backend dependencies
â”‚
â”‚â”€â”€ frontend/             # React app
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/   # UI components
â”‚   â”‚   â”œâ”€â”€ pages/        # Main pages
â”‚   â”‚   â””â”€â”€ App.js        # Main React app
â”‚   â””â”€â”€ package.json      # Frontend dependencies
â”‚
â”‚â”€â”€ README.md             # Project documentation

âš¡ Installation
ğŸ”¹ Backend (FastAPI)
cd backend
python -m venv venv
source venv/bin/activate   # (Linux/Mac)
venv\Scripts\activate      # (Windows)
pip install -r requirements.txt
uvicorn main:app --reload


Demo (UI Preview)


[ğŸ¤ Start Recording]
[âœ… Analyze] â†’ "á‹°áŠ•á‰ áŠ›á‹ áŠ¥áŒ…áŒ á‹°áˆµ á‰¥áˆá‰³áˆ" â†’ ğŸŸ¢ Positive



ğŸ‘¨â€ğŸ’» Author

Dawit Shibabaw
ğŸš€ Data Scientist | AI Researcher | Call Center AI Solutions


---

ğŸ‘‰ Do you also want me to include **deployment steps** (e.g., Docker + Nginx for production) in this README so itâ€™s ready for real-world call center integration?


